{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1 Machine learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/go555666/UTS_ML2019_ID13510577/blob/master/Assignment_1_Machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpBqH4FnV0Qb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Draft and Experiment Area**\n",
        "\n",
        "**1. First impression**\n",
        "\n",
        "'Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection'\n",
        "\n",
        "At introduction, this paper presents drawbacks about popular methods which have used on face recognition and suggested new method to show better performance than existing methods. Based on the introduction, this paper is going to show Fishface method which performs high rate accuracy of face recognition under variability of lighting and different facial expressions compared with other methods.\n",
        "\n",
        "\n",
        "\n",
        "Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "\n",
        "**2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list, compare the list with people around you who have chosen the same or a similar paper.**\n",
        "\n",
        "dimensionality reduction\n",
        "3D linear subspace\n",
        "Lambertian surfaces\n",
        "Principal Component Analysis(PCA)\n",
        "Eigenface\n",
        "Linear Discriminant \n",
        "Linear projection\n",
        "\n",
        "\n",
        "**3. (During the next 7 days) Re-consider the central problem of the paper.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RB8XkmnM9qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXntlUReORRI",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "123cf8cf-c0c8-4635-d31a-ab505d01612c"
      },
      "source": [
        "upload = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c9dc172-af21-4894-a14e-48e6b80c31e7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1c9dc172-af21-4894-a14e-48e6b80c31e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Screen Shot 2019-08-27 at 2.21.18 pm.png to Screen Shot 2019-08-27 at 2.21.18 pm (1).png\n",
            "Saving Screen Shot 2019-08-28 at 9.54.01 am.png to Screen Shot 2019-08-28 at 9.54.01 am.png\n",
            "Saving Screen Shot 2019-08-28 at 9.54.12 am.png to Screen Shot 2019-08-28 at 9.54.12 am.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZLU4sItlMr5",
        "colab_type": "text"
      },
      "source": [
        "# **Review Report on \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-UxvINLmlmO",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Since 2017, FaceId, is facial-recognition technology for unlocking smartphone to use, have been applied to IphoneX. After then, almost of smartphones from Samsung, Xiaomi followed the trend. Face recognition is used not only in smart phones but also in many places in our lives due to its convenience and certainty of identity. For example, the entrance of the laboratory or company and criminal investigation. However, for facial recognition, there are many variables which are always changed from time to time. The variable can be lighting variability, face expression, background, puffy face in morning and angle of viewpoint. Frequently, but not often, recognition errors result from a combination of these conditions. \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\" paper suggests a new method, Fisherfaces, which is insensitive on variations in facial expressions and lighting in comparison with other methods which were widely used at the time of the paper publication.\n",
        "\n",
        "This report is consisted of 5 sections to review \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\" paper based on my understanding. In content section, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arOvJ-t-lq_r",
        "colab_type": "text"
      },
      "source": [
        "# **Content**\n",
        "\n",
        "The research is about presenting effective method on face recognition under variability of lighting and facial expressions. In this paper, the proposed method to increase the accuracy of face recognition in light variability and facial expression change is Fisherfaces. In order to proving the excellence of Fisherfaces methods, there are three comparative group models. Firstly, Correlation is the simplest method among them. As a nearest neighbor classifier, it classifies the test images by placing them in the image space and labeling the image’s class based on the image of the learning set closest to that location. This method is easy and reasonable to see, but there are fatal weaknesses in changes to light and facial expressions rather than fixed images. This method is easy and reasonable to look at, but it has a fatal weakness when the learning dataset images and the test images’ the intensity and direction of the light sources and facial expressions are different. Due to variability of lighting and facial expressions, corresponding points spread out compared with the images captured in same conditions. Also, it needs to heavy storage and computation.\n",
        "\n",
        "\n",
        "Second method is Eigenfaces. Principal components analysis (PCA) covers Correlation’s drawbacks such as expensive computation and large capacity by dimensionality reduction. In PCA, dimensionality reducing is used to maximize distribution of samples. When a dataset contained $N_{}$\n",
        "images, in which $n_{}$ is number of pixel for each image, each image takes values in $n_{}$-dimensional image space. Through linear transformation, $n_{}$-dimensional image space is mapped into an $m_{}$-dimensional feature space and, as a result of the process, the new feature vectors is generated. In here, because figure $n_{}$ must be bigger than figure $m_{}$, dimensional reducing is occurred. Based on the new feature vectors, the projection $W_{opt}$ can arrange $m_{}$ largest eigenvalues with degree of scatter. Eigenface is the interpretation of new feature vectors thus obtained as an image. The front eigenfaces (1st ~ 3rd largest eigenvalues) represent the elements common to the data (the overall shape of the face) and the more detailed the difference information backwards (4th ~ $m_{}$ th largest eigenvalues) (ref). However, although this method maximizes the scatter between the different classes to clarify the distinction between the different classes, there is a possibility of maximizing the scatter within the class so that it cannot be clustered inside the class. \n",
        "\n",
        "Thirdly, Linear Subspaces used Lambertian surfaces with no shadow, presenting images in 3D linear subspace, see <Fig.1>.\n",
        "<img src='https://drive.google.com/file/d/1quE81iSi9agsfy-VMfR9n6XLC9jzMXoW/view?usp=sharing' alt='<Fig.1 Images in 3D linear subspace>'>\n",
        "\n",
        "In Lambertian surfaces, regardless of the direction in which the diffusion surface is viewed, the lighting reflects the same luminance in all directions. White paper or full moon is close to Lambertian surfaces(ref). Due to this character, the classification to figure out Lambertian surfaces is insensitive under various lighting conditions. In case of each class, for generating a 3D basis which is located in 3D linear subspace, 3 or more sample images are used. After, by computing distance test image’s basis between classes basis, test image is recognized as the nearest class. Although Linear Subspace perfectly work at ideal situation, without shadowing and noise, self-shadowing and facial expression impedes linear subspace. Also, because recognition proceeds in a similar way to Correlation method, it has needs to heavy storage and computation that Correlation has.\n",
        "\n",
        "Compared to the three methods above, Fisherfaces applied Fisher’s Linear Discriminant (FLD) to solve the Eigenfaces problem which is while maximizing the scatter between the different classes to clarify the distinction between the different classes, the scatter within the class also increases and it has bad effects on recognition. Simple image transfers to eigenface through PDA, dimensionality reduction which means simple image project to face subspace. The result image projects using LDA to make linear discriminant in subspace with eigenface vectors. For recognition, by applying a classifier (In this paper, nearest neighbor), new image is going to recognize based on a weighed metric derived by the eigenvalue of the LDA. This minimizes the variation within the class and keeps the variation between classes to a maximum.\n",
        "\n",
        "Two experiments were conducted through the 4 methods. In first experiment, dataset is divided into 5 subsets with variation in lighting. The space in the direction of the light source, which can be parameterized by the spherical angle, was sampled in 15° increments. For better performance, on correlation and Eigenface images, normalization is applied. As a result of the experiment, Fisherface got the lowest error rates among 4 methods. Linear Subspace got the competitive result on error rates, but it takes around three times storage and calculation time than Fisherface. In case of Eigenface, excepting the first 3 front eigenfaces components, which means the elements common to the data, has a good effect on error rates.\n",
        "\n",
        "In second experiment, it was set for testing facial expression and glasses recognition. For one subject, it consisted of 10 images which include 1 with glasses, 1 without glasses, 3 images under different lighting conditions and 5 with various facial expressions. For better performance, on correlation and Eigenface images, normalization is applied. As a result of the experiment, Fisherface show best performance among 4 methods. However, although Fisherface’s good face recognition performance under lighting variability and various facial expression, a technique to mask the shadows or noise parts is required to overcome performance degrades when a lot of shadowing in image.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9NpzJihlrU9",
        "colab_type": "text"
      },
      "source": [
        "# Innovation\n",
        "\n",
        "Face recognition by using machine has been a very important area in the field of computer vision. This is because it is the best system for user convenience (Zhao et al. 2003). However, there are 3 difficulties on face recognition. Firstly, recognition rate varies depending on the lighting or distance from camera. Secondly, it is difficult in practical use because facial angle, facial expression, and facial shape change continuously. Thirdly, problems caused by changes in appearance such as beard, eyebrows, glasses and makeup(Wang, Li & Wang 2004). Fisherfaces is a technology that is strong against the above-mentioned difficulties compared to Eigenface, which was the latest technology in 1997.\n",
        "\n",
        "\"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\" paper had published in 1997. According to (Barrett 1997), there were four techniques used for face recognition in 1997. Neural Networks express facial features in a condensed way. But it has difficulty with training and, under same circumstance, the performance of Neural Networks no better than Eigenfaces method. Wavelets and Elastic Matching uses frequency conversion and is effective in dealing with changes in posture and facial expression(Zhan et al. 2006). However, it is computationally expensive compared to recognition rate. Elastic grid matching exploits the grid which can flexibly distort (within constraints) to find the most match between the two images. It is insensitive under variability lighting and facial expressions. But, when Elastic grid matching is applied, time performance is relatively poor. Lastly, by using PCA technique, dimensionality reduction, Eigenface maximizes the scatter of all projected simples and take advantages in terms of computation and storage. However, Error rates tend to increase under the conditions of light and facial changes. As such, the methods in 1997 had drawback compared to other comparison groups. Under these circumstances, Fisherfaces that is insensitive to light and facial expressions changes have been innovative, using FLD to reduce scatter within the class that increase in Eigenfaces. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOICbE25lrag",
        "colab_type": "text"
      },
      "source": [
        "# **Technical quality**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBn_NcCPlrd9",
        "colab_type": "text"
      },
      "source": [
        "# **Application and X-factor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvJ-_wG7lrhm",
        "colab_type": "text"
      },
      "source": [
        "# **Presentation**\n",
        "\n",
        "The overall structure of the paper is simple and clear. The paper is consisted of 3 main parts, introduction, methods and experimental results and conclusion. In introduction, it presents the aim of paper and their approach to achieve the purpose. And introduction provides a brief description of how the methods and experimental results sections are organized, and under what conditions. Introduction takes the role of guide to help reader to expect following contents. In methods section, it explains about 4 methods’ principles and disadvantages. This part was clear in terms of structure, not long, and explaining the core principles. However, It would have been easier for readers to understand the content if the concept of core terms, such as PCA and FLD, or basic term, such as Lambertian surface, linear projection, and eigenvector, were described in ‘Background and related work’ section. In experimental results and conclusion, the results of the experiments were clearly explained by providing graphs and tables with explanations, and the summary was briefly summarized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgf7fcFCmDzM",
        "colab_type": "text"
      },
      "source": [
        "# **References**"
      ]
    }
  ]
}